---
title: "flowr"
subtitle: "Streamlining Workflows"
output: 
    html_document: 
    keep_md: yes
packagedocs:
    toc: false
navpills: |
  <li><a href='docs.html'>Docs</a></li>
  <li><a href='rd.html'>Package Ref</a></li>
  <li><a href='news.html'>News</a></li>
  <li><a href='https://github.com/sahilseth/flowr'>Github <i class='fa fa-github'></i></a></li>
---


[![Build Status](https://travis-ci.org/sahilseth/flowr.svg?branch=master)](https://travis-ci.org/sahilseth/flowr)
[![cran](http://www.r-pkg.org/badges/version/flowr)](http://cran.rstudio.com/web/packages/flowr/index.html)
[![codecov.io](http://codecov.io/github/sahilseth/flowr/coverage.svg?branch=devel)](http://codecov.io/github/sahilseth/flowr?branch=devel)
![downloads](http://cranlogs.r-pkg.org/badges/grand-total/flowr)


This framework allows you to design and implement complex pipelines, and
deploy them on your institution's computing cluster. This has been built
keeping in mind the needs of bioinformatics workflows. However, it is
easily extendable to any field where a series of steps (shell commands)
are to be executed in a (work)flow.

Highlights
----------

- Effectively process a **multi-step pipeline**, spawning it
across the computing cluster
- Example: 
	- A typical case in next-generation sequencing is of processing tens of
   [fastqs](http://en.wikipedia.org/wiki/FASTQ_format) for a sample,
   [mapping](http://en.wikipedia.org/wiki/Sequence_alignment) them to a reference genome.
	- Each step may require a range resources from in terms of CPU, RAM etc.
		- Consider we have 50 files using 10 cores each for step A (500 cores total).
		- Next step uses one core each (50 cores total).
		- Say step C merges them, and uses only 1 core.
     several machines, for one sample
	- Some pipelines may reserve the maximum, example say 500 cores throught, 
	flowr would handle the **surge**, reserving 500, 50 or 1; when needed.
	- Now consider the run has 10 samples, all of them would be procesed in
	 parallel, spawning **thousands of cores**.
-   **Reproducible** and **transparent**, with cleanly structured execution logs
-   **Track** and **re-run** flows
-   **Lean** and **Portable**, with easy installation
-   Supports **multiple cluster computing platforms** (torque, lsf, sge, slurm ...)

### A few lines, to get started:

``` {r, eval=FALSE}
## From the official R repository (may be a few versions behind)
install.packages("flowr")

## OR

install.packages(devtools)
devtools::install_github("sahilseth/flowr")

library(flowr) ## load the library
setup() ## copy flowr bash script; and create a folder flowr under home.
```

-   Here is a shiny app,
    [flow\_creator](https://sseth.shinyapps.io/flow_creator) which helps
    you build a flow.
-   A few [slides](http://sahilseth.github.io/slides/flowrintro)
    providing a quick overview.



Aknowledgements
---------------

-   Jianhua Zhang
-   Samir Amin
-   Kadir Akdemir
-   Ethan Mao
-   Henry Song
-   An excellent resource for writing your own R packages:
    r-pkgs.had.co.nz

<!--why this license http://kbroman.org/pkg_primer/pages/licenses.html -->
